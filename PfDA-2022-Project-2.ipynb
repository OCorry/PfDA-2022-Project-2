{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6321591",
   "metadata": {},
   "source": [
    " # <font color=darkblue>Programming for Data Analysis 2022 - Project 2</font>\n",
    "\n",
    "## <font color=darkblue>Orla Corry</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9a3b53",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Table of Contents</font>\n",
    "***\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "\n",
    "\n",
    "- [Importing Libraries](#Importing-Libraries)\n",
    "\n",
    "\n",
    "- [Reading in the csv file](#Reading-in-the-csv-file)\n",
    "\n",
    "\n",
    "- [Analysis/review of the dataset](#Analysis/review-of-the-dataset)\n",
    "\n",
    "\n",
    "- [Literature review on classifiers](#Literature-review-on-classifiers)\n",
    "\n",
    "\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402bbe6f",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Introduction</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31cd3c",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Importing Libraries</font>\n",
    "***\n",
    "\n",
    "For this project I will be importing the following Libraries:\n",
    "\n",
    "1. **Pandas** - to read in the dataset and to analyse data that is in tabular form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b311a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d017722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table{float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table{float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc9b9d",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Reading in the csv file</font>\n",
    "***\n",
    "I have sourced the Wesconsin Breast Cancer Dataset from <a href=\"https://github.com/jeffheaton/aifh/blob/master/vol1/python-examples/datasets/breast-cancer-wisconsin.csv\" target=\"_top\">Heaton. J (Github), 2013</a>. To pull the actual csv URL from Heaton's Github, I clicked on the *Raw* tab and copied & pasted the URL that was provided for the raw data. Below, I have read in the the csv file to Python using the built in library <a href=\"https://pandas.pydata.org/docs/\" target=\"_top\">Pandas</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83711859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the csv file using pandas\n",
    "# Using dataset from https://github.com/jeffheaton/aifh/blob/master/vol1/python-examples/datasets/breast-cancer-wisconsin.csv\n",
    "dataset = (\"https://raw.githubusercontent.com/jeffheaton/aifh/master/vol1/python-examples/datasets/breast-cancer-wisconsin.csv\")\n",
    "df = pd.read_csv (dataset) #storing the read in csv dataframe as df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a62093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>size_uniformity</th>\n",
       "      <th>shape_uniformity</th>\n",
       "      <th>marginal_adhesion</th>\n",
       "      <th>epithelial_size</th>\n",
       "      <th>bare_nucleoli</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  clump_thickness  size_uniformity  shape_uniformity  \\\n",
       "0    1000025                5                1                 1   \n",
       "1    1002945                5                4                 4   \n",
       "2    1015425                3                1                 1   \n",
       "3    1016277                6                8                 8   \n",
       "4    1017023                4                1                 1   \n",
       "..       ...              ...              ...               ...   \n",
       "694   776715                3                1                 1   \n",
       "695   841769                2                1                 1   \n",
       "696   888820                5               10                10   \n",
       "697   897471                4                8                 6   \n",
       "698   897471                4                8                 8   \n",
       "\n",
       "     marginal_adhesion  epithelial_size bare_nucleoli  bland_chromatin  \\\n",
       "0                    1                2             1                3   \n",
       "1                    5                7            10                3   \n",
       "2                    1                2             2                3   \n",
       "3                    1                3             4                3   \n",
       "4                    3                2             1                3   \n",
       "..                 ...              ...           ...              ...   \n",
       "694                  1                3             2                1   \n",
       "695                  1                2             1                1   \n",
       "696                  3                7             3                8   \n",
       "697                  4                3             4               10   \n",
       "698                  5                4             5               10   \n",
       "\n",
       "     normal_nucleoli  mitoses  class  \n",
       "0                  1        1      2  \n",
       "1                  2        1      2  \n",
       "2                  1        1      2  \n",
       "3                  7        1      2  \n",
       "4                  1        1      2  \n",
       "..               ...      ...    ...  \n",
       "694                1        1      2  \n",
       "695                1        1      2  \n",
       "696               10        2      4  \n",
       "697                6        1      4  \n",
       "698                4        1      4  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the dataframe (df) to make sure the csv file read in to Python properly\n",
    "df\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce22a7b8",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Analysis/review of the dataset</font>\n",
    "***\n",
    "The Breast Cancer Wisconsin (Original) Data Set is a classification dataset that records measurements under a number of attributes <a href=\"http://odds.cs.stonybrook.edu/breast-cancer-wisconsin-original-dataset/\" target=\"_top\">ODDS. (2022)</a> in order to predict whether a case is either of class benign or class malignant. These attributes will be discussed in more detail later on.\n",
    "\n",
    "Using the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html\" target=\"_top\">df.shape</a> command on the dataframe above, we can see that the dataset comprises of 699 instances/cases (rows) of data across 11 attributes (columns). \n",
    "\n",
    "The 699 rows of data were gathered over a period of time which spanned from January 1989 through to November 1991. The data gathered over the 8 periods during this time is organised into 8 groups. \n",
    "\n",
    "There are 11 features or attributes to this dataset, all of which are of data type *integer*. Starting at column index 0 through to index 10, the first column contains the *id* of the case/instance which are integers with multiple digits. From column index 1 to index 9 the 9 attributes, namely; *clump thickness*, *size uniformity*, *shape uniformity*, *marginal adhesion*, *epithelial size*, *bare nucleoli*, *bland chromatin*, *normal nucleoli* and *mitoses* are given values ranging from 1 to 10. According to <a href=\"https://www.journalbinet.com/uploads/2/1/0/0/21005390/67.02.09.2020_analysis_of_wisconsin_breast_cancer_original_dataset_using_data_mining_and_machine_learning_algorithms_for_breast_cancer_prediction.pdf\" target=\"_top\">Ahmed, T. et al. (2020)</a> the larger the value for these 9 attruibutes, the greater the chance of the case being malignant. Finally, the last column contains the attribute *class* which contains values either 2 or 4 where 2 represents benign and 4 represents malignant <a href=\"https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\" target=\"_top\">Wolberg, W.H. (1992)</a>. **Table 1.** below summarises all of the attributes (excluding the *id** attribute) and what values they can take.\n",
    "\n",
    "<ins>**Table 1.**</ins>\n",
    "\n",
    "\n",
    "\n",
    "|*Attributes*      |*Value*|\n",
    "|:-----------------|:--:\n",
    "|\n",
    "|Clump thickness   |1-10|\n",
    "|Size uniformity   |1-10| \n",
    "|Shape uniformity  |1-10|\n",
    "|Marginal Adheasion|1-10|\n",
    "|Epithelial size   |1-10| \n",
    "|Bare nucleoli     |1-10|\n",
    "|Bland chromatin   |1-10| \n",
    "|Normal nucleoli   |1-10| \n",
    "|Mitoses           |1-10|\n",
    "|Class             |2 = benign & 4= malignant|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfef881a",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Literature review on classifiers</font>\n",
    "***\n",
    "While there are may different variations of definitions of classifiers in machine learning, according to the <a href=\"https://scikit-learn.org/stable/\" target=\"_top\">scikit-learn documentation (2022)</a>, classifiers identify which category an object belongs to. A classifier can be defined as an algorithm that automatically assigns data points to a range of categories or classes and there are two main models; supervised and unsupervised <a href=\"https://www.indeed.com/career-advice/career-development/classifiers-in-machine-learning\" target=\"_top\">Indeed Editorial Team. (2022)</a>.\n",
    "\n",
    "This section sets out to research some previous studies done using the Wisconsin Breast Cancer (Original) Data Set, and to establish what classifiers were used and compare their performances. \n",
    "\n",
    "#### <ins>Study 1</ins>\n",
    "\n",
    "\n",
    "A study titled *Study and Analysis of Breast Cancer Data* carried out by <a href=\"https://www.ijert.org/research/study-and-analysis-of-breast-cancer-data-IJERTCONV5IS21015.pdf\" target=\"_top\">Manoli. N.S and Padma. S.K (2017) </a> used two forms of classifiers namely; the Naive-Bayes Classifier and the Support Vector Machine (SVM) classifier along with a further feature called **<a href=\"https://www.upgrad.com/blog/pca-in-machine-learning/\" target=\"_top\">Principal Component Analysis (PCA) </a>**. A PCA is a machine learning technique used on datasets with many input variables to reduce the dimensions of the dataset by identifying relationships between the input variables and coupling them together. This is used because if dataset has a lot of input attributes, it can lead to the classifier failing <a href=\"https://www.upgrad.com/blog/pca-in-machine-learning/\" target=\"_top\">Vadapalli. P. (2020) </a>.\n",
    "\n",
    "This Manoli. N.S & Padma. S.K (2017) study found that both of the classifiers were very accurate as they both had accuracy rates above 95%. The Naive Bayes Classifier scored an accuracy rate of 95.71% for the whole data (data where PCA was not applied) and 97.14% accuracy where the PCA feature was applied. However, the Support Vector Machine (SVM) was a little superior with a accuracy result of 97.14% for the whole data (data where PCA was not applied) and 97.86% accuracy where the PCA feature was applied. \n",
    "\n",
    "#### <ins>Study 2</ins>\n",
    "<a href=\"https://www.journalbinet.com/uploads/2/1/0/0/21005390/67.02.09.2020_analysis_of_wisconsin_breast_cancer_original_dataset_using_data_mining_and_machine_learning_algorithms_for_breast_cancer_prediction.pdf\" target=\"_top\">Ahmed. T. et al (2020)</a>\n",
    " carried out a study titled *Analysis of Wisconsin Breast Cancer original dataset using data mining and machine learning algorithms for breast cancer prediction* on a number of different classifiers. Again, Naïve Bayes was one of their chosen classifiers. Others to note were Multilayer perceptron (MLP), J48 and Support vector machine (SVM).\n",
    " \n",
    " \n",
    "The study found the Naïve Bayes to be the highest performing classifier with an accuracy rate of 97.2779%. Following this was the Multilayer Perceptron (MLP) Classifer with an accuracy rate of 96.1318. The lowest scoring classifier in this study was the J48 classifier at 94.2693. \n",
    "\n",
    "Ahmed. T. et al (2020) then dug deeper into the Naïve Bayes classifier. They carried out different trials by removing a single feature (or attribute) at a time to establish how each attribute effected the classifiers performance. They found that by removing the *Single Epithelial Cell Size* attribute from the dataset, the classifier was most accurate. Their most accurate result came about by splitting the data into 85.5% train data and 14.65% test data. The outcome of this was that the classifier was 99.0099% accurate. \n",
    "\n",
    "Again, this study reveals that the Naive Bayes classifier is most effective and accuarate classifier from the the classifiers they studied. One thing to note here is that in this study the Principal Component Analysis (PCA) technique was not used. However, in their conclusion, they did refer to using PCA in future studies. Incorporating the PCA may have an impact on the accuracy of the Naive Bayes classifier.\n",
    "\n",
    "\n",
    "#### <ins>Study 3</ins>\n",
    "<a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6408508\" target=\"_top\">G. Salama et al. (2012)</a> published a paper titled *Experimental Comparison of Classifiers for Breast Cancer Diagnosis* in which they investigated the performance of a number of classifiers. They focused on decision tree (J48), Multi-LayerPerception\n",
    "(MLP), Naive Bayes (NB), Sequential Minimal Optimization (SMO), and Instance Based for K-Nearest neighbor (IBK). \n",
    "\n",
    "By using a single classifier on it's own, they found that Sequential Minimal Optimization (SMO) classifier was the most accurate at an accuracy rate of 96.9957%, followed by the Naive Bayes (NB) classifier at 95.9943% accuracy. The decision tree (J48) was the least accurate of the classifiers tested at an accuracy of 95.1359%. \n",
    "\n",
    "However, they delved into their accuracy more by *fusing* or combining the classifiers together to create *multi-classifiers*. They found that by fusing SMO, IBK, NB and J48 classifiers, the overall accuracy was 97.2818% which was more accurate than using any of the classifiers individually. \n",
    "\n",
    "Furthermore, by implementing Principal Component Analysis (PCA) to combine related attributes and consequently reduce the number of input variables, they found their most accurate multi-classifier of all. This was a fusion of the J48 and MLP classifiers. This is interesting because originally, using the classifiers individually, the J48 and MLP were the two least accurate classifiers of those examined in the study. \n",
    "\n",
    "\n",
    "#### <ins>Study 4</ins>\n",
    "A paper titled *Performance Analysis on Three Breast Cancer Datasets using Ensemble Classifiers Techniques* by <a href=\"file:///C:/Users/Admin/Downloads/kkuenjadmin,+8-23-20.pdf\" target=\"_top\">Arach. S. & Bouden. H. (2019)</a> also looked into classifiers used on the Wisconsin Breast Cancer Data Set. They looked into the accuracy of 6 classifiers; Bayesian networks (BN), Multi-LayerPerception (MLP), decision tree (J48), Sequential Minimal Optimization (SMO), Random Forest (RF) and \n",
    "Instance Based for K-Nearest neighbor (IBK) based on cross validation of 10-fold as a method of testing. *Cross validation of 10-fold*  means that the dataset is divided randomly into 10 parts. Nine of the parts are used for training and one part is used for testing. The process is then repeated 10 times so a different tenth is tested <a href=\"https://www.kdnuggets.com/2018/01/training-test-sets-cross-validation.html\" target=\"_top\">Zacharski. R. (2022)</a>  \n",
    "\n",
    "In their study, the authors incorporated a feature selection method called **<a href=\"https://www.scikit-yb.org/en/latest/api/model_selection/rfecv.html\" target=\"_top\">Recursive Feature Elimination (RFE)</a>** which eliminates the least significant features (attributes) until the correct number of features is reached <a href=\"https://www.scikit-yb.org/en/latest/api/model_selection/rfecv.html\" target=\"_top\">The scikit-yb developers (2019)</a>. \n",
    "\n",
    "\n",
    "The results of the study show that used individually, the Baysian Networks (BN) classifier was the most accurate at an accuracy rate of 97.28%. The least accurate classifier was the decision tree (J48) at 95.15% accuracy. \n",
    "Combining (BN) with other classifiers gave interesting results. Combining BN with SMO resulted in a decrease in the accuracy, and the similarly fusing BN with MLP reduced the accuracy also. Combining 4 classifiers; BN RF SMO and IBK increased accuracy to 97.99%. This had test also included the Principal Component Analysis (PCA).\n",
    "\n",
    "Their study found that the removal of the Recursive Feature Elimination (RFE), feature selection method reduced the accuracy of the classifiers across the board, both individually and as multi - classifiers. \n",
    "\n",
    "\n",
    "#### <ins>Study 5</ins>\n",
    "<a href=\"https://ijnaa.semnan.ac.ir/article_5965_a1ca78998e8760f2915afc8b1d037e64.pdf\" target=\"_top\">Al-Joda. A.A, et al. (2021).</a> comprised a study called *Comparison of classification techniques based on medical datasets* in which they focused on three classifiers; Support Vector Machine (SVM), Adaptive Boosting (AdaBoost) and  Random forests (RF). They used these classifiers on two datasets, one of which being the Wisconsin Breast Cancer Data Set.\n",
    "\n",
    "Their findings showed that the Adaptive Boosting (AdaBoost) was the most accurate of the three classifiers used with an accuracy of 100%. The other two classifiers; Support Vector Machine (SVM) and Random forests (RF) were also found to be very accurate at a rate of 0.976% accuracy. \n",
    "\n",
    "\n",
    "#### <ins>Study 6</ins>\n",
    "A study by <a href=\"file:///C:/Users/Admin/Downloads/monther,+12300-Article+Text-36825-1-6-20210211%20(1).pdf\" target=\"_top\">Abdulkareema S.A and Abdulkareem Z.O.(2021).</a> titled *An Evaluation of the Wisconsin Breast Cancer Dataset using Ensemble Classifiers and RFE Feature Selection Technique* focuses on two classifiers, namely; Random Forest (RF) and eXtreme Gradient Boost (XGBoost) along with the inclusion of a feature selection technique, Recursive Feature Elimination (RFE).\n",
    "\n",
    "For the study the authors split the data 80/20, where 80% of the dataset was training data and 20% of the data was testing data\n",
    "\n",
    "Their work shows that again both of the classifiers are quite accurate with accuracy rates of 97.07% and 98.53% for the RF and XGBoost respectively. This experiment did not include the feature selection technique and hence all of the features(attributes) were inlcuded in the calculation.\n",
    "\n",
    "However with the inclusion of the Recursive Feature Elimination feature selection technique, the results improved further. The accuracy of the RF classifier increased to 98.05% and the accuracy of the XGBoost increased to 99.02%. \n",
    "\n",
    "The authors provided a \n",
    "**<a href=\"https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/\" target=\"_top\">confusion matrix.</a>**\n",
    "which gives results of the XGBoost classifier and the RFE feature selection technique. This matrix shows that the XGBoost classifier along with the RFE technique predicted all of the malignant data correctly and was also very accuarte with the benign data, having predicted 2 cases to be malignant but were actually benign.\n",
    "\n",
    "\n",
    "#### <ins>Study 7</ins>\n",
    "A study titled *Breast Cancer Classification Using Machine Learning* <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8391453\" target=\"_top\">M. Amrane. et al. (2018)</a> focused on k-Nearest Neighbors (KNN) and Naive Bayes (NB) classifiers. \n",
    "\n",
    "This study did not include any feature selection technique or any other form of technique to cut down or couple up the features. \n",
    "\n",
    "Again this study was conclusive in its findings that both of the classifiers were effective and accurate. The KNN classifier was just a little ahead of the NB classifier with rates of 97.51% and 96.19% respectively. However, the authors did conclude that if the dataset had been bigger, KNN would not have been as efficient as the algorithm is more complex and would take longer to run. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a87e47",
   "metadata": {},
   "source": [
    "## <font color=darkblue>References</font>\n",
    "***\n",
    "\n",
    "1. Heaton J. Github. breast-cancer-wisconsin.csv (2013) https://github.com/jeffheaton/aifh/blob/master/vol1/python-examples/datasets/breast-cancer-wisconsin.csv\n",
    "\n",
    "\n",
    "2. Pandas Documentation. (2022). https://pandas.pydata.org/docs/\n",
    "\n",
    "\n",
    "3. Pandas. pandas.DataFrame.shape. (2022). https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html\n",
    "\n",
    "\n",
    "4. ODDS. Breast Cancer Wisconsin (Original) dataset. (2022). http://odds.cs.stonybrook.edu/breast-cancer-wisconsin-original-dataset/\n",
    "\n",
    "\n",
    "4. Ahmed. T, Omtiaz. N and Karmakar. A.(2020). Analysis of Wisconsin Breast Cancer original dataset using data\n",
    "mining and machine learning algorithms for breast cancer\n",
    "prediction\n",
    "https://www.journalbinet.com/uploads/2/1/0/0/21005390/67.02.09.2020_analysis_of_wisconsin_breast_cancer_original_dataset_using_data_mining_and_machine_learning_algorithms_for_breast_cancer_prediction.pdf\n",
    "\n",
    "\n",
    "5. Wolberg, W. H. (1992) Breast Cancer Wisconsin (Original) Data Set. https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
    "\n",
    "\n",
    "7. How to align table in Jupyter Notebook. Deepsim Acadamey. (2021). https://www.youtube.com/watch?v=_1jg0FlzpUs\n",
    "\n",
    "\n",
    "8. scikit-learn. (2022). https://scikit-learn.org/stable/\n",
    "\n",
    "\n",
    "\n",
    "9. Indeed Editorial Team. Machine Learning Classifiers: Definition and 5 Types. (2022). https://www.indeed.com/career-advice/career-development/classifiers-in-machine-learning\n",
    "\n",
    "\n",
    "10. Manoli. N.S & Padma. S.K. Study and Analysis of Breast Cancer Data (2017) https://www.ijert.org/research/study-and-analysis-of-breast-cancer-data-IJERTCONV5IS21015.pdf\n",
    "\n",
    "\n",
    "11. Vadapalli. P. (2020). PCA in Machine Learning: Assumptions, Steps to Apply & Applications. https://www.upgrad.com/blog/pca-in-machine-learning/\n",
    "\n",
    "\n",
    "12. Ahmed.T. et al. (2020). Analysis of Wisconsin Breast Cancer original dataset using data mining and machine learning algorithms for breast cancer prediction. https://www.journalbinet.com/uploads/2/1/0/0/21005390/67.02.09.2020_analysis_of_wisconsin_breast_cancer_original_dataset_using_data_mining_and_machine_learning_algorithms_for_breast_cancer_prediction.pdf\n",
    "\n",
    "\n",
    "13. G. Salama et al. (2012). Experimental Comparison of Classifiers for Breast Cancer Diagnosis. https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6408508 , https://www.semanticscholar.org/paper/Experimental-comparison-of-classifiers-for-breast-Salama-Abdelhalim/1437a72d1445abed6ae51020d0d041c63ef57bf3\n",
    "\n",
    "\n",
    "14. Arach. S,  Bouden. H (2019). Performance Analysis on Three Breast Cancer Datasets using Ensemble Classifiers Techniques http://ijmcs.future-in-tech.net/14.4/R-Arach.pdf\n",
    "\n",
    "\n",
    "\n",
    "15. Zacharski. R. Training Sets, Test Sets, and 10-fold Cross-validation. (2022). https://www.kdnuggets.com/2018/01/training-test-sets-cross-validation.html\n",
    "\n",
    "\n",
    "16. The scikit-yb developers. Recursive Feature Elimination. (2019). https://www.scikit-yb.org/en/latest/api/model_selection/rfecv.html\n",
    "\n",
    "\n",
    "17. Al-Joda. A.A, et al. (2021). Comparison of classification techniques based on medical datasets. https://ijnaa.semnan.ac.ir/article_5965_a1ca78998e8760f2915afc8b1d037e64.pdf\n",
    "\n",
    "\n",
    "18. Bhandari. A. Analytics Vidhya. Everything you Should Know about Confusion Matrix for Machine Learning. (2022). https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/\n",
    "\n",
    "\n",
    "19. M. Amrane, S. Oukid, I. Gagaoua and T. Ensarİ, \"Breast cancer classification using machine learning,\" 2018 Electric Electronics, Computer Science, Biomedical Engineerings' Meeting (EBBT), 2018, pp. 1-4, doi: 10.1109/EBBT.2018.8391453. https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8391453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc0de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742c8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
